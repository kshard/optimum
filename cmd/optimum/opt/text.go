//
// Copyright (C) 2024 Dmitry Kolesnikov
//
// This file may be modified and distributed under the terms
// of the MIT license.  See the LICENSE file for details.
// https://github.com/kshard/optimum
//

package opt

import (
	"bufio"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"strings"

	"github.com/fogfish/curie"
	"github.com/fogfish/schemaorg"
	"github.com/kshard/optimum"
	"github.com/kshard/optimum/cmd/optimum/opt/common"
	"github.com/kshard/optimum/sentences"
	"github.com/schollz/progressbar/v3"
	"github.com/spf13/cobra"
)

const TYPE_TEXT = "text"

func init() {
	rootCmd.AddCommand(textCmd)

	textCmd.AddCommand(textListCmd)

	textCmd.AddCommand(textCreateCmd)
	textCreateCmd.Flags().StringVarP(&textOpts, "json", "j", "", "json config file")

	textCmd.AddCommand(textCommitCmd)

	textCmd.AddCommand(textUploadCmd)
	textUploadCmd.Flags().IntVar(&textUploadBuf, "buf", 4, "upload buffer in MB (default 4MB)")

	textCmd.AddCommand(textStreamCmd)
	textStreamCmd.Flags().IntVar(&textChunkSize, "chunk", 100, "streaming chunk size (default 10)")

	textCmd.AddCommand(textQueryCmd)
	textQueryCmd.Flags().StringVarP(&textQueryFile, "file", "f", "", "text queries batch file")
	textQueryCmd.Flags().IntVar(&textQuerySize, "size", 20, "size of the resultset")

	textCmd.AddCommand(textRemoveCmd)
}

var (
	textOpts      string
	textUploadBuf int
	textChunkSize int
	textQueryFile string
	textQuerySize int
)

var textCmd = &cobra.Command{
	Use:   "text",
	Short: "Operates `text` data structures.",
	Long: `
The data structure clusters textual content using nearest neighborhood and
provides efficient lookup. Below are some key areas where "text" structure
is applicable:

* Text Search and Retrieval: The struct can be used in search engines and document
retrieval systems to quickly find similar documents on high-dimensional
text embeddings.

* Content-Based Recommendations: The struct is useful for finding similar items in
recommendation systems, such as finding related products, movies, or music
tracks based on embeddings vectors. It helps quickly locate users or items
with similar behavior patterns.

* Personalized Content: When a system needs to recommend personalized content
(e.g., news articles, blog posts), the struct can quickly find the most relevant
content based on a user's preferences or behavior.

* Semantic Search: In NLP, The struct is used to find semantically similar phrases,
sentences, or documents by comparing embeddings generated by text  models.

* Chatbots and Conversational AI: The struct can be used to match user queries to a set
of predefined responses or intents based on similarity.
`,
	SilenceUsage: true,
	Run:          text,
}

func text(cmd *cobra.Command, args []string) {
	cmd.Help()
}

//------------------------------------------------------------------------------

var textListCmd = &cobra.Command{
	Use:   "list",
	Short: "List all instances of `text` data structure.",
	Long:  common.AboutList(TYPE_TEXT, ""),
	Example: `
optimum text list -u $HOST
optimum text list -u $HOST -r $ROLE
`,
	SilenceUsage: true,
	RunE:         textList,
}

func textList(cmd *cobra.Command, args []string) (err error) {
	cli, err := stack()
	if err != nil {
		return err
	}

	return common.List(optimum.New(cli, host), TYPE_TEXT)
}

//------------------------------------------------------------------------------

var textCreateCmd = &cobra.Command{
	Use:   "create",
	Short: "Create new instance of `text` data structure.",
	Long: common.AboutCreate(TYPE_TEXT, `
The algorithm "text" is an approximation nearest neighbor search of natural
language content. It enhances the usability of "approximate nearest
neighbor search in high-dimensional spaces" by integrating embeddings and
supporting indexing and retrieval of textual blocks instead of pure vectors.

Config algorithm through primary parameters:
  - "embeddings.model" the model id of the model to calculate embeddings vector.

  - "embeddings.dimension" is a size of output embeddings vector.

  - if "hnsw.*" is defined, it enables the use of the Hierarchical Navigable
    Small World (HNSW) algorithm for approximation nearest neighbor search.

  - "hnsw.M" and "hnsw.M0" controls the maximum number of connections per node,
    balancing between memory usage and search efficiency.  M0 defines
    the connection density on the graph's base layer, while M regulates it on
    the intermediate layers.

  - "hnsw.efConstruction" determines the number of candidate nodes evaluated
    during graph construction, influencing both the construction time and
    the accuracy of the graph.

  - "hnsw.surface" is vector distance function.

Example configuration and default values:	
  {
    "embeddings": {
      "model": "amazon.titan-embed-text-v2:0",
      "dimension": 256,       // enum {256, 512, 1024} 
    },
    "hnsw": {
      "m":  8,                // number in range of [4, 1024]
      "m0": 64,               // number in range of [4, 1024]
      "efConstruction": 200,  // number in range of [200, 1000]
      "surface": "cosine"     // enum {"cosine", "euclidean"}
    }
  }

`),
	Example: `
optimum text create -u $HOST -n example -j path/to/config.json
optimum text create -u $HOST -r $ROLE -n example -j path/to/config.json
`,
	SilenceUsage: true,
	RunE:         textCreate,
}

func textCreate(cmd *cobra.Command, args []string) (err error) {
	cli, err := stack()
	if err != nil {
		return err
	}

	return common.Create(optimum.New(cli, host), curie.New("%s:%s", TYPE_TEXT, name), textOpts)
}

//------------------------------------------------------------------------------

var textCommitCmd = &cobra.Command{
	Use:   "commit",
	Short: "Commit earlier uploaded datasets into `text` instance.",
	Long:  common.AboutCommit(TYPE_TEXT, ""),
	Example: `
optimum text commit -u $HOST -n example
optimum text commit -u $HOST -r $ROLE -n example
`,
	SilenceUsage: true,
	RunE:         textCommit,
}

func textCommit(cmd *cobra.Command, args []string) (err error) {
	cli, err := stack()
	if err != nil {
		return err
	}

	return common.Commit(optimum.New(cli, host), curie.New("%s:%s", TYPE_TEXT, name))
}

//------------------------------------------------------------------------------

var textUploadCmd = &cobra.Command{
	Use:   "upload",
	Short: "Upload `text` datasets.",
	Long: `
Upload "text" dataset to server. It accepts either text or json data. The type
of the file is determined by the extension.

Text files (.txt)

Each line of the file is a text block to be indexed as whole. The format does
not carry on any metadata, it is tailored for pure text processing:

  his garret was under the roof of a high, ... cupboard than a room.
  it's simply a fantasy to amuse myself; a plaything!

Json files (.json)

Each line of the file is a json object that carries on the text and metadata to
be indexed:

  {"text": "his garret was...", "isPartOf": "https://example.com/abc123", ...}
  {"text": "a fantasy to amuse...", "isPartOf": "https://example.com/abc456", ...}

The full schema of json object is following
  {
    "text": "...",       // short text block less than 4KB.
    "isPartOf": "...",   // URL of the original doc from which the text is derived.
    "headline": ["..."], // headline(s) of the text.
    "keywords": ["..."], // relevant keywords for the text.
    "links": ["..."]     // external URIs associated with the text. 
  }

`,
	Example: `
optimum text upload -u $HOST -n example path/to/data.txt
optimum text upload -u $HOST -r $ROLE -n example path/to/data.json
`,
	SilenceUsage: true,
	Args:         cobra.ExactArgs(1),
	RunE:         textUpload,
}

func textUpload(cmd *cobra.Command, args []string) (err error) {
	isJson := strings.HasSuffix(args[0], "json")
	fd, err := os.Open(args[0])
	if err != nil {
		return err
	}
	defer fd.Close()

	fi, err := fd.Stat()
	if err != nil {
		return err
	}

	cli, err := stack()
	if err != nil {
		return err
	}

	stream := sentences.NewWriter(cli, host, curie.New("%s:%s", TYPE_TEXT, name), hnswUploadBuf*1024*1024)

	r := io.TeeReader(fd,
		progressbar.DefaultBytes(
			fi.Size(),
			"==> uploading",
		),
	)

	scanner := bufio.NewScanner(r)
	for scanner.Scan() {
		text := scanner.Text()

		var sentence sentences.Sentence
		if isJson {
			json.Unmarshal([]byte(text), &sentence)
		} else {
			sentence = sentences.Sentence{
				Text: schemaorg.Text(text),
			}
		}

		err := stream.Write(context.Background(), sentence)
		if err != nil {
			return err
		}
	}

	if err := scanner.Err(); err != nil {
		return err
	}

	if err := stream.Sync(context.Background()); err != nil {
		return err
	}

	return nil
}

//------------------------------------------------------------------------------

var textStreamCmd = &cobra.Command{
	Use:   "stream",
	Short: "Stream `text` datasets.",
	Long: `
Upload "text" dataset to server. It accepts either text or json data. The type
of the file is determined by the extension.

Text files (.txt)

Each line of the file is a text block to be indexed as whole. The format does
not carry on any metadata, it is tailored for pure text processing:

  his garret was under the roof of a high, ... cupboard than a room.
  it's simply a fantasy to amuse myself; a plaything!

Json files (.json)

Each line of the file is a json object that carries on the text and metadata to
be indexed:

  {"text": "his garret was...", "isPartOf": "https://example.com/abc123", ...}
  {"text": "a fantasy to amuse...", "isPartOf": "https://example.com/abc456", ...}

The full schema of json object is following
  {
    "text": "...",       // short text block less than 4KB.
    "isPartOf": "...",   // URL of the original doc from which the text is derived.
    "headline": ["..."], // headline(s) of the text.
		"keywords": ["..."], // relevant keywords for the text.
		"links": ["..."]     // external URIs associated with the text. 
  }

`,
	Example: `
optimum text stream -u $HOST -n example path/to/data.json
optimum text stream -u $HOST -r $ROLE -n example path/to/data.txt
`,
	SilenceUsage: true,
	Args:         cobra.ExactArgs(1),
	RunE:         textStream,
}

func textStream(cmd *cobra.Command, args []string) (err error) {
	isJson := strings.HasSuffix(args[0], "json")
	fd, err := os.Open(args[0])
	if err != nil {
		return err
	}
	defer fd.Close()

	fi, err := fd.Stat()
	if err != nil {
		return err
	}

	cli, err := stack()
	if err != nil {
		return err
	}

	api := sentences.New(cli, host)

	r := io.TeeReader(fd,
		progressbar.DefaultBytes(
			fi.Size(),
			"==> uploading",
		),
	)

	scanner := bufio.NewScanner(r)
	for scanner.Scan() {
		bag := make([]sentences.Sentence, 0)
		for i, has := 0, true; i < textChunkSize && has; i, has = i+1, scanner.Scan() {
			text := scanner.Text()

			var sentence sentences.Sentence
			if isJson {
				json.Unmarshal([]byte(text), &sentence)
			} else {
				sentence = sentences.Sentence{
					Text: schemaorg.Text(text),
				}
			}

			bag = append(bag, sentence)
		}

		if len(bag) > 0 {
			err := api.Write(context.Background(), curie.New("%s:%s", TYPE_TEXT, name), bag)
			if err != nil {
				return err
			}
		}
	}

	return nil
}

//------------------------------------------------------------------------------

var textQueryCmd = &cobra.Command{
	Use:   "query",
	Short: "Query instance of `text` data structure.",
	Long: `
Query "text" data structure instance. It accepts text as input, where
each line is query to evaluate: 

  his garret was under the roof of a high, ... cupboard than a room.
  it's simply a fantasy to amuse myself; a plaything!

The file format is identical to the upload textual and can be re-used as is.
`,
	Example: `
optimum text query -u $HOST -n example -f path/to/query.txt
optimum text query -u $HOST -r $ROLE -n example -f path/to/query.txt
optimum text query -u $HOST -n example "under the roof"
`,
	SilenceUsage: true,
	RunE:         textQuery,
}

func textQuery(cmd *cobra.Command, args []string) (err error) {
	if len(textQueryFile) != 0 {
		return textQueryWithFile(cmd, args)
	}

	q := strings.Join(args, " ")
	if len(q) == 0 {
		return fmt.Errorf("query is not defined")
	}

	cli, err := stack()
	if err != nil {
		return err
	}

	api := sentences.New(cli, host)

	query := sentences.Query{Text: q, K: textQuerySize}
	rs, err := api.Query(context.Background(), curie.New("%s:%s", TYPE_TEXT, name), query)
	if err != nil {
		return err
	}

	for _, hit := range rs.Hits {
		fmt.Printf("%1.4f : %32s \n", hit.Rank, hit.Text)
	}

	return nil
}

func textQueryWithFile(cmd *cobra.Command, args []string) (err error) {
	fd, err := os.Open(textQueryFile)
	if err != nil {
		return err
	}
	defer fd.Close()

	cli, err := stack()
	if err != nil {
		return err
	}

	api := sentences.New(cli, host)

	n := 1
	scanner := bufio.NewScanner(fd)
	for scanner.Scan() {
		query := sentences.Query{Text: scanner.Text(), K: textQuerySize}
		rs, err := api.Query(context.Background(), curie.New("%s:%s", TYPE_TEXT, name), query)
		if err != nil {
			return err
		}

		fmt.Printf("\nQuery %d (took %s) | %s (vsn %s, size %d)\n", n, rs.Took, rs.Source.Cask, rs.Source.Version, rs.Source.Size)
		fmt.Printf("  > %s\n", query.Text)
		for _, hit := range rs.Hits {
			fmt.Printf("  %f : %32s \n", hit.Rank, hit.Text)
		}

		n++
	}

	if err := scanner.Err(); err != nil {
		return err
	}

	return nil
}

//------------------------------------------------------------------------------

var textRemoveCmd = &cobra.Command{
	Use:   "remove",
	Short: "Remove instance of `text` data structure.",
	Long:  common.AboutRemove(TYPE_TEXT, ""),
	Example: `
optimum text commit -u $HOST -n example
optimum text commit -u $HOST -r $ROLE -n example
`,
	SilenceUsage: true,
	RunE:         textRemove,
}

func textRemove(cmd *cobra.Command, args []string) (err error) {
	cli, err := stack()
	if err != nil {
		return err
	}

	return common.Remove(optimum.New(cli, host), curie.New("%s:%s", TYPE_TEXT, name))
}
